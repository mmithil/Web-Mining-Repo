{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Created on Mar 18, 2016\n",
    "@author: pushkar\n",
    "'''\n",
    "\n",
    "import urllib2\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import time\n",
    "import re\n",
    "\n",
    "\n",
    "def getAmazonDetails(isbn):\n",
    "    \n",
    "    with open('csv_files/amazon_book_ratings.csv', 'a') as csvfile_ratings, open('csv_files/amazon_book_reviews.csv', 'a') as csvfile_reviews:\n",
    "        ##Create file headers and writer\n",
    "        ratings_fieldnames = ['book_isbn', 'avg_rating', 'five_rating', 'four_rating', 'three_rating', 'two_rating', 'one_rating' ]\n",
    "        writer = csv.DictWriter(csvfile_ratings, delimiter=',', lineterminator='\\n', fieldnames=ratings_fieldnames)\n",
    "        ##writer.writeheader()\n",
    "         \n",
    "        reviews_fieldnames = ['book_isbn', 'review']            \n",
    "        writer_book = csv.DictWriter(csvfile_reviews, delimiter=',', lineterminator='\\n', fieldnames=reviews_fieldnames)\n",
    "        ##writer_book.writeheader()\n",
    "\n",
    "        ##Get Overall details of the book    \n",
    "        req = urllib2.Request('http://www.amazon.com/product-reviews/' + isbn + '?ie=UTF8&showViewpoints=1&sortBy=helpful&pageNumber=1', headers={ 'User-Agent': 'Mozilla/5.0 (X11; U; Linux i686) Gecko/20071127 Firefox/2.0.0.11' })\n",
    "        html = urllib2.urlopen(req).read()\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "        avgRatingTemp = soup.find_all('div',{'class':\"a-row averageStarRatingNumerical\"})[0].get_text()\n",
    "        avgRating = re.findall('\\d+\\.\\d+', avgRatingTemp)[0]\n",
    "    \n",
    "        try:\n",
    "            fiveStarRatingTemp = soup.find_all('a',{'class':\"a-size-small a-link-normal 5star histogram-review-count\"})[0].get_text()\n",
    "            fiveStarRating = fiveStarRatingTemp.strip('%')\n",
    "        except:\n",
    "            fiveStarRating = 0\n",
    "\n",
    "        try:\n",
    "            fourStarRatingTemp = soup.find_all('a',{'class':\"a-size-small a-link-normal 4star histogram-review-count\"})[0].get_text()\n",
    "            fourStarRating = fourStarRatingTemp.strip('%')\n",
    "        except:\n",
    "            fourStarRating = 0\n",
    "\n",
    "        try:\n",
    "            threeStarRatingTemp = soup.find_all('a',{'class':\"a-size-small a-link-normal 3star histogram-review-count\"})[0].get_text()\n",
    "            threeStarRating = threeStarRatingTemp.strip('%')\n",
    "        except:\n",
    "            threeStarRating = 0\n",
    "\n",
    "        try:\n",
    "            twoStarRatingTemp = soup.find_all('a',{'class':\"a-size-small a-link-normal 2star histogram-review-count\"})[0].get_text()\n",
    "            twoStarRating = twoStarRatingTemp.strip('%')\n",
    "        except:\n",
    "            twoStarRating = 0\n",
    "\n",
    "        try:\n",
    "            oneStarRatingTemp = soup.find_all('a',{'class':\"a-size-small a-link-normal 1star histogram-review-count\"})[0].get_text()\n",
    "            oneStarRating = oneStarRatingTemp.strip('%')\n",
    "        except:\n",
    "            oneStarRating = 0\n",
    "\n",
    "        writer.writerow({'book_isbn': isbn, 'avg_rating': avgRating, 'five_rating': fiveStarRating, \n",
    "                         'four_rating': fourStarRating, 'three_rating': threeStarRating, 'two_rating': twoStarRating,\n",
    "                         'one_rating': oneStarRating})\n",
    "    \n",
    "        ##Get top 20 helpful review of book\n",
    "        for pagenumber in range(1,3):\n",
    "            req = urllib2.Request('http://www.amazon.com/product-reviews/' + isbn + '?ie=UTF8&showViewpoints=1&sortBy=helpful&pageNumber='+ str(pagenumber), headers={ 'User-Agent': 'Mozilla/5.0 (X11; U; Linux i686) Gecko/20071127 Firefox/2.0.0.11' })\n",
    "            html = urllib2.urlopen(req).read()\n",
    "            soup = BeautifulSoup(html, 'html.parser')    \n",
    "            for i in range(0,10):\n",
    "                try:\n",
    "                    review = soup.find_all('div',{'class':\"a-section review\"})[i].contents[3].get_text().encode('UTF-8')\n",
    "                    #print review\n",
    "                    writer_book.writerow({'book_isbn': isbn, 'review': review})\n",
    "                except:\n",
    "                    print \"No Reviews ISBN - \" + isbn\n",
    "                \n",
    "#getAmazonDetails('0940650703')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random number: 5829332\n",
      "getting information for user id:5829332\n",
      "User number:0\n",
      "Saved user data for user id:5829332\n",
      "Checking for books in shelf: read for user id:5829332\n",
      "https://www.goodreads.com/review/list/5829332.xml?key=i3Zsl7r13oHEQCjv1vXw&v=2&shelf=read\n",
      "Fetching data for book with isbn:0767900383 and id:5829332\n",
      "Exception!!\n",
      "End of Program\n"
     ]
    }
   ],
   "source": [
    "import urllib2\n",
    "import csv\n",
    "import time\n",
    "import sys\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def getval(root, element):\n",
    "    try:\n",
    "        ret = root.find(element).text\n",
    "        if ret is None:\n",
    "            return \"\"\n",
    "        else:\n",
    "            return ret.encode(\"utf8\")\n",
    "    except:\n",
    "        return \"\"\n",
    "    \n",
    "\n",
    "with open('csv_files/amazon_book_ratings.csv', 'w') as csvfile_ratings, open('csv_files/amazon_book_reviews.csv', 'w') as csvfile_reviews:\n",
    "    ##Create file headers and writer\n",
    "    ratings_fieldnames = ['book_isbn', 'avg_rating', 'five_rating', 'four_rating', 'three_rating', 'two_rating', 'one_rating' ]\n",
    "    writer = csv.DictWriter(csvfile_ratings, delimiter=',', lineterminator='\\n', fieldnames=ratings_fieldnames)\n",
    "    writer.writeheader()\n",
    "         \n",
    "    reviews_fieldnames = ['book_isbn', 'review']            \n",
    "    writer_book = csv.DictWriter(csvfile_reviews, delimiter=',', lineterminator='\\n', fieldnames=reviews_fieldnames)\n",
    "    writer_book.writeheader()\n",
    "\n",
    "with open('csv_files/user_data.csv', 'w') as csvfile, open('csv_files/book_data.csv', 'w') as csvfile_book, open('csv_files/book_author.csv', 'w') as csvfile_author:\n",
    "    fieldnames = ['id', 'name','user_name', 'profile_url','image_url', 'about', 'age', 'gender', \n",
    "                  'location','joined','last_active' ]\n",
    "    writer = csv.DictWriter(csvfile, delimiter = ',', lineterminator = '\\n', fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    book_fieldnames = [\n",
    "                        'user_id',\n",
    "                        'b_id',\n",
    "                        'shelf',\n",
    "                        'isbn', \n",
    "                        'isbn13',\n",
    "                        'text_reviews_count',\n",
    "                        'title',\n",
    "                        'image_url',\n",
    "                        'link',\n",
    "                        'num_pages',\n",
    "                        'b_format',\n",
    "                        'publisher',\n",
    "                        'publication_day', \n",
    "                        'publication_year', \n",
    "                        'publication_month',\n",
    "                        'average_rating', \n",
    "                        'ratings_count', \n",
    "                        'description', \n",
    "                        'published',\n",
    "                        'children',\n",
    "                        'religion',\n",
    "                        'history',\n",
    "                        'math',\n",
    "                        'anatology',\n",
    "                        'poetry',\n",
    "                        'encyclopedia',\n",
    "                        'dictionaries',\n",
    "                        'comics',\n",
    "                        'art',\n",
    "                        'cookbook',\n",
    "                        'diaries',\n",
    "                        'journals',\n",
    "                        'prayer-books',\n",
    "                        'series',\n",
    "                        'trilogy',\n",
    "                        'biographies',\n",
    "                        'autobiographies',\n",
    "                        'fantasy']\n",
    "    book_shelf = ['children',\n",
    "                  'religion',\n",
    "                  'history',\n",
    "                  'math',\n",
    "                  'anatology',\n",
    "                  'poetry',\n",
    "                  'encyclopedia',\n",
    "                  'dictionaries',\n",
    "                  'comics',\n",
    "                  'art',\n",
    "                  'cookbook',\n",
    "                  'diaries',\n",
    "                  'journals',\n",
    "                  'prayer-books',\n",
    "                  'series',\n",
    "                  'trilogy',\n",
    "                  'biographies',\n",
    "                  'autobiographies',\n",
    "                  'fantasy']\n",
    "    \n",
    "    writer_book = csv.DictWriter(csvfile_book, delimiter = ',', lineterminator = '\\n', fieldnames=book_fieldnames)\n",
    "    writer_book.writeheader()\n",
    "    author_fieldnames = [\n",
    "                        'u_id',\n",
    "                        'b_id',\n",
    "                        'a_id',\n",
    "                        'name',\n",
    "                        'average_rating',\n",
    "                        'ratings_count',\n",
    "                        'text_reviews_count']\n",
    "    writer_author = csv.DictWriter(csvfile_author, delimiter = ',', lineterminator = '\\n', fieldnames = author_fieldnames)\n",
    "    writer_author.writeheader()\n",
    "\n",
    "    lst = []\n",
    "    i = 0\n",
    "    \n",
    "    while i < 1:   \n",
    "        try:     \n",
    "            clear_output()\n",
    "            #time.sleep(1)\n",
    "            clear_output()\n",
    "            c = random.randint(5625001, 7500000) #7500000 625000\n",
    "            print \"random number: \" + str(c)    \n",
    "\n",
    "            if (c not in lst):\n",
    "                print \"getting information for user id:\"+ str(c)\n",
    "                lst.append(c)\n",
    "                url = 'https://www.goodreads.com/user/show/'+ str(c) +'.xml?key=i3Zsl7r13oHEQCjv1vXw'\n",
    "                response = urllib2.urlopen(url)\n",
    "                user_data_xml = response.read()\n",
    "                #write xml to file\n",
    "                print \"User number:\" + str(i)\n",
    "                i = i + 1\n",
    "                f = open(\"xml_docs/user\"+ str(c) +\".xml\", \"w\")\n",
    "                try:\n",
    "                    f.write(user_data_xml)\n",
    "                finally:\n",
    "                    f.close()\n",
    "                #root = ET.fromstring()\n",
    "                root = ET.parse(\"xml_docs/user\"+ str(c) +\".xml\").getroot()\n",
    "                os.remove(\"xml_docs/user\"+ str(c) +\".xml\")\n",
    "                user_element = root.find('user')\n",
    "                id = getval(user_element,'id')\n",
    "                name = getval(user_element,'name')\n",
    "                user_name = getval(user_element,'user_name')\n",
    "                profile_url = getval(user_element,'link')\n",
    "                image_url = getval(user_element,'image_url')\n",
    "                about = getval(user_element,'about')\n",
    "                age = getval(user_element,'age')\n",
    "                gender = getval(user_element,'gender')\n",
    "                location = getval(user_element,'location')\n",
    "                joined = getval(user_element,'joined')\n",
    "                last_active = getval(user_element,'last_active')\n",
    "                writer.writerow({'id': id, 'name' : name,'user_name' : user_name,\n",
    "                                  'profile_url' : profile_url,'image_url' : image_url,\n",
    "                                 'about' : about, 'age': age, 'gender' : gender, \n",
    "                                 'location' : location, 'joined' : joined, 'last_active': last_active})\n",
    "                print \"Saved user data for user id:\" + str(c)\n",
    "            \n",
    "            \n",
    "                # get list of user shelves\n",
    "            \n",
    "                user_shelves_root =  user_element.find('user_shelves')\n",
    "            \n",
    "                user_shelf_list = []\n",
    "            \n",
    "                for user_shelf in user_shelves_root.findall(\"user_shelf\"):\n",
    "                    shelf = getval(user_shelf,\"name\")\n",
    "                    #Books on Shelf\n",
    "                    print \"Checking for books in shelf: \" + shelf + \" for user id:\" + str(c)\n",
    "                    \n",
    "                    shelf_url = \"https://www.goodreads.com/review/list/\"+ str(c) +\".xml?key=i3Zsl7r13oHEQCjv1vXw&v=2&shelf=\" + shelf\n",
    "                    #time.sleep(1)\n",
    "                    print shelf_url\n",
    "                    response = urllib2.urlopen(shelf_url)\n",
    "                    shelf_data_xml = response.read()\n",
    "                    # write xml to file\n",
    "                    f = open(\"xml_docs/user_shelf_\" + shelf + \"_\"+ str(c) + \".xml\", \"w\")\n",
    "                    try:\n",
    "                        f.write(shelf_data_xml)\n",
    "                    finally:\n",
    "                        f.close()\n",
    "                    \n",
    "                    shelf_root = ET.parse(\"xml_docs/user_shelf_\" + shelf + \"_\"+ str(c) + \".xml\").getroot()\n",
    "                    \n",
    "                    os.remove(\"xml_docs/user_shelf_\" + shelf + \"_\"+ str(c) + \".xml\")\n",
    "                    reviews = shelf_root.find(\"reviews\")\n",
    "                    for review in reviews.findall(\"review\"):\n",
    "                        for book in review.findall(\"book\"):\n",
    "                            b_id = getval(book,\"id\")\n",
    "                            isbn = getval(book,\"isbn\")\n",
    "                            print \"Fetching data for book with isbn:\" + str(isbn) + \" and id:\" + str(id)\n",
    "                            isbn13 = getval(book,\"isbn13\")\n",
    "                            text_reviews_count = getval(book,\"text_reviews_count\")\n",
    "                            title = getval(book,\"title\")\n",
    "                            image_url = getval(book,\"image_url\")\n",
    "                            link = getval(book,\"link\")\n",
    "                            num_pages = getval(book,\"num_pages\")\n",
    "                            b_format = getval(book,\"format\")\n",
    "                            publisher = getval(book,\"publisher\")\n",
    "                            publication_day = getval(book,\"publication_day\")\n",
    "                            publication_year = getval(book, \"publication_year\") \n",
    "                            publication_month = getval(book,\"publication_month\")\n",
    "                            average_rating = getval(book,\"average_rating\")\n",
    "                            ratings_count = getval(book,\"rating_count\")\n",
    "                            description = getval(book,\"description\")\n",
    "                            published = getval(book,\"published\")\n",
    "                            \n",
    "                            #get number of books on each type of shelf\n",
    "                            book_url = 'https://www.goodreads.com/book/show/'+b_id+'.xml?key=i3Zsl7r13oHEQCjv1vXw'\n",
    "                            response = urllib2.urlopen(shelf_url)\n",
    "                            book_data_xml = response.read()\n",
    "                            # write xml to file\n",
    "                            f = open(\"xml_docs/book_data_\" + str(b_id) + \".xml\", \"w\")\n",
    "                            try:\n",
    "                                f.write(book_data_xml)\n",
    "                            finally:\n",
    "                                f.close()\n",
    "                    \n",
    "                            book_root = ET.parse(\"xml_docs/user_shelf_\" + shelf + \"_\"+ str(c) + \".xml\").getroot()\n",
    "                            os.remove(\"xml_docs/book_data_\" + str(b_id) + \".xml\")\n",
    "                            \n",
    "                            book_root = book_root.find(\"book\")\n",
    "                            book_shelves = book_root.find(\"popular_shelves\")\n",
    "                            \n",
    "                            for shelf in book_shelves.findall(\"shelf\"):\n",
    "                                attributes = shelf.attrib\n",
    "                                name = attributes['name']\n",
    "                                count = attributes['count']\n",
    "                                if(name == 'children')\n",
    "                                if(name =='religion')\n",
    "                                if(name =='history')\n",
    "                                if(name =='math')\n",
    "                                if(name =='anatology')\n",
    "                                if(name =='poetry')\n",
    "                                if(name =='encyclopedia')\n",
    "                                if(name =='dictionaries')\n",
    "                                if(name =='comics')\n",
    "                                if(name =='art')\n",
    "                                if(name =='cookbook')\n",
    "                                if(name =='diaries')\n",
    "                                if(name =='journals')\n",
    "                                if(name =='prayer-books')\n",
    "                                if(name =='series')\n",
    "                                if(name =='trilogy')\n",
    "                                if(name =='biographies')\n",
    "                                if(name =='autobiographies')\n",
    "                                if(name =='fantasy')\n",
    "                            \n",
    "                            \n",
    "                            getAmazonDetails(isbn)\n",
    "                            print \"Fetched review data from Amazon for book :\" + title\n",
    "                            writer_book.writerow({\n",
    "                                'user_id': id,\n",
    "                                'b_id' : b_id ,\n",
    "                                'shelf' : shelf,\n",
    "                                'isbn' : isbn, \n",
    "                                'isbn13': isbn13,\n",
    "                                'text_reviews_count' : text_reviews_count,\n",
    "                                'title' : title,\n",
    "                                'image_url' : image_url,\n",
    "                                'link' : link,\n",
    "                                'num_pages' : num_pages,\n",
    "                                'b_format' : b_format,\n",
    "                                'publisher' : publisher,\n",
    "                                'publication_day' : publication_day, \n",
    "                                'publication_year' : publication_year, \n",
    "                                'publication_month' : publication_month,\n",
    "                                'average_rating' : average_rating, \n",
    "                                'ratings_count' : ratings_count, \n",
    "                                'description' : description \n",
    "                                'children' : ,\n",
    "                                'religion' : ,\n",
    "                                'history' : ,\n",
    "                                'math': ,\n",
    "                                'anatology' : ,\n",
    "                                'poetry' : ,\n",
    "                                'encyclopedia' : ,\n",
    "                                'dictionaries' : ,\n",
    "                                'comics' : ,\n",
    "                                'art' : ,\n",
    "                                'cookbook' : ,\n",
    "                                'diaries' : ,\n",
    "                                'journals' : ,\n",
    "                                'prayer-books' : ,\n",
    "                                'series' : ,\n",
    "                                'trilogy' : ,\n",
    "                                'biographies' : ,\n",
    "                                'autobiographies' : ,\n",
    "                                'fantasy' : })\n",
    "\n",
    "                            print \"Data written on csv for book:\" + title\n",
    "\n",
    "                            authors = book.find(\"authors\")\n",
    "                            for author in authors.findall(\"author\"):\n",
    "                                a_id = getval(author,\"id\")\n",
    "                                name = getval(author,\"name\")\n",
    "                                average_rating = getval(author,\"average_rating\")\n",
    "                                ratings_count = getval(author,\"ratings_count\")\n",
    "                                text_reviews_count = getval(author,\"text_reviews_count\")\n",
    "                                writer_author.writerow({'u_id': id,\n",
    "                                                        'b_id' : b_id,\n",
    "                                                        'a_id' : a_id,\n",
    "                                                        'name' : name,\n",
    "                                                        'average_rating' : average_rating,\n",
    "                                                        'ratings_count' : ratings_count,\n",
    "                                                        'text_reviews_count' : text_reviews_count})\n",
    "        except:\n",
    "            #time.sleep(1)\n",
    "            print \"Exception!!\"\n",
    "    print \"End of Program\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
